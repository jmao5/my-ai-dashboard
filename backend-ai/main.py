from fastapi import FastAPI, Depends, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from sqlalchemy.orm import Session
import database
import os
import google.generativeai as genai # ğŸ‘ˆ êµ¬ê¸€ ë¼ì´ë¸ŒëŸ¬ë¦¬

# 1. DB ì´ˆê¸°í™”
database.Base.metadata.create_all(bind=database.engine)

# 2. Gemini ì„¤ì •
GOOGLE_API_KEY = os.getenv("GEMINI_API_KEY")
if not GOOGLE_API_KEY:
    print("âš ï¸ ê²½ê³ : GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
else:
    genai.configure(api_key=GOOGLE_API_KEY)

# ì‚¬ìš©í•  ëª¨ë¸ ì„ íƒ
if not GOOGLE_API_KEY:
    print("âš ï¸ ê²½ê³ : GEMINI_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
else:
    genai.configure(api_key=GOOGLE_API_KEY)

    # ğŸ‘‡ [ìˆ˜ì •] ê³ ë¯¼í•  ê²ƒ ì—†ì´ 'gemini-2.5-flash'ë¡œ ê³ ì •!
    # (ëª©ë¡ì— ìˆëŠ” ì´ë¦„ ê·¸ëŒ€ë¡œ ì‚¬ìš©)
    target_model = 'gemini-2.5-flash'

    print(f"ğŸš€ ìµœì‹  ëª¨ë¸ '{target_model}'ì„ ë¡œë“œí•©ë‹ˆë‹¤...")
    try:
        model = genai.GenerativeModel(target_model)
        print("âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ì„¤ì • ì‹¤íŒ¨: {e}")
        print("   í˜¹ì‹œ API í‚¤ ê¶Œí•œ ë¬¸ì œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class ChatRequest(BaseModel):
    message: str

def get_db():
    db = database.SessionLocal()
    try:
        yield db
    finally:
        db.close()

@app.get("/")
def read_root():
    return {"message": "Gemini AI Server is Running!"}

@app.get("/api/ai-status")
def get_ai_status():
    status = "Online" if GOOGLE_API_KEY else "Key Missing"
    return {
        "status": status,
        "model": "Google Gemini Pro",
        "message": "ì§„ì§œ ì¸ê³µì§€ëŠ¥ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤."
    }

@app.get("/api/chat/history")
def get_chat_history(db: Session = Depends(get_db)):
    # ìµœê·¼ 50ê°œë§Œ ê°€ì ¸ì˜¤ê¸° (ë„ˆë¬´ ë§ìœ¼ë©´ ëŠë¦¬ë‹ˆê¹Œ)
    history = db.query(database.ChatHistory).order_by(database.ChatHistory.id.asc()).limit(50).all()
    return [{"role": h.role, "text": h.message} for h in history]

# 3. í•µì‹¬: ì±„íŒ… API (Gemini ì—°ë™)
@app.post("/api/chat")
async def chat_with_ai(request: ChatRequest, db: Session = Depends(get_db)):
    user_msg = request.message

    # (1) ìœ ì € ë©”ì‹œì§€ DB ì €ì¥
    db_user_msg = database.ChatHistory(role="user", message=user_msg)
    db.add(db_user_msg)
    db.commit()

    try:
        # (2) Geminiì—ê²Œ ì§ˆë¬¸ ë˜ì§€ê¸°
        if not GOOGLE_API_KEY:
            ai_response = "API í‚¤ê°€ ì—†ì–´ì„œ ëŒ€ë‹µí•  ìˆ˜ ì—†ì–´ìš”. docker-compose.ymlì„ í™•ì¸í•´ì£¼ì„¸ìš”."
        else:
            # generate_contentê°€ ì‹¤ì œ êµ¬ê¸€ ì„œë²„ë¡œ ì§ˆë¬¸ì„ ë³´ëƒ…ë‹ˆë‹¤.
            response = model.generate_content(user_msg)
            ai_response = response.text

    except Exception as e:
        ai_response = f"ìƒê°í•˜ë‹¤ê°€ ì—ëŸ¬ê°€ ë‚¬ì–´ìš”: {str(e)}"
        print(f"Gemini Error: {e}")

    # (3) AI ë‹µë³€ DB ì €ì¥
    db_ai_msg = database.ChatHistory(role="bot", message=ai_response)
    db.add(db_ai_msg)
    db.commit()

    return {"reply": ai_response}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)