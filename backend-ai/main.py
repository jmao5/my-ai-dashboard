from fastapi import FastAPI, Depends, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from sqlalchemy.orm import Session
import database
import os
import google.generativeai as genai # ğŸ‘ˆ êµ¬ê¸€ ë¼ì´ë¸ŒëŸ¬ë¦¬

# 1. DB ì´ˆê¸°í™”
database.Base.metadata.create_all(bind=database.engine)

# 2. Gemini ì„¤ì •
GOOGLE_API_KEY = os.getenv("GEMINI_API_KEY")
if not GOOGLE_API_KEY:
    print("âš ï¸ ê²½ê³ : GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
else:
    genai.configure(api_key=GOOGLE_API_KEY)

# ì‚¬ìš©í•  ëª¨ë¸ ì„ íƒ
if not GOOGLE_API_KEY:
    print("âš ï¸ ê²½ê³ : GEMINI_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
else:
    genai.configure(api_key=GOOGLE_API_KEY)

    print("\nğŸ” --- Google API ì œê³µ ëª¨ë¸ ëª©ë¡ (ìƒìœ„ 20ê°œ) ---")
    try:
        # (1) generateContentë¥¼ ì§€ì›í•˜ëŠ” ëª¨ë“  ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°
        all_models = [
            m for m in genai.list_models()
            if 'generateContent' in m.supported_generation_methods
        ]

        # (2) ê·¸ëƒ¥ ìˆëŠ” ê·¸ëŒ€ë¡œ 20ê°œ ì¶œë ¥ (ì´ë¦„ ì •ë ¬ ì—†ì´ êµ¬ê¸€ì´ ì£¼ëŠ” ìˆœì„œëŒ€ë¡œ)
        for i, m in enumerate(all_models[:20]):
            print(f"[{i+1:02d}] {m.name}")

        print("---------------------------------------------------\n")

        # (3) ì¼ë‹¨ ì„œë²„ê°€ ì¼œì ¸ì•¼ í•˜ë‹ˆ, ê°€ì¥ ì•ˆì „í•œ 'gemini-2.5-flash'ë¡œ ì„¤ì •í•´ë‘¡ë‹ˆë‹¤.
        # ë¡œê·¸ë¥¼ ë³´ì‹œê³  ë§ˆìŒì— ë“œëŠ” ëª¨ë¸ ì´ë¦„ì´ ìˆë‹¤ë©´ ë‚˜ì¤‘ì— ì—¬ê¸°ë¥¼ ë°”ê¾¸ë©´ ë©ë‹ˆë‹¤.
        target_model_name = 'gemini-2.5-flash'

        # í˜¹ì‹œ ëª©ë¡ì— ìš°ë¦¬ê°€ ì“°ë ¤ëŠ” ê²Œ ìˆëŠ”ì§€ í™•ì¸
        if any(m.name == f"models/{target_model_name}" for m in all_models):
            print(f"âœ… '{target_model_name}' ëª¨ë¸ì„ ì°¾ì•„ ì—°ê²°í–ˆìŠµë‹ˆë‹¤.")
            model = genai.GenerativeModel(target_model_name)
        else:
            print(f"âš ï¸ '{target_model_name}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëª©ë¡ì˜ ì²« ë²ˆì§¸ ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            if all_models:
                first_model = all_models[0].name
                print(f"ğŸ‘‰ ëŒ€ì²´ ëª¨ë¸: {first_model}")
                model = genai.GenerativeModel(first_model)
            else:
                print("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ í•˜ë‚˜ë„ ì—†ìŠµë‹ˆë‹¤!")

    except Exception as e:
        print(f"âŒ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        print("   ê¸°ë³¸ê°’ 'gemini-2.5-flash'ë¡œ ê°•ì œ ì„¤ì •í•©ë‹ˆë‹¤.")
        model = genai.GenerativeModel('gemini-2.5-flash')

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class ChatRequest(BaseModel):
    message: str

def get_db():
    db = database.SessionLocal()
    try:
        yield db
    finally:
        db.close()

@app.get("/")
def read_root():
    return {"message": "Gemini AI Server is Running!"}

@app.get("/api/ai-status")
def get_ai_status():
    status = "Online" if GOOGLE_API_KEY else "Key Missing"
    return {
        "status": status,
        "model": "Google Gemini Pro",
        "message": "ì§„ì§œ ì¸ê³µì§€ëŠ¥ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤."
    }

@app.get("/api/chat/history")
def get_chat_history(db: Session = Depends(get_db)):
    # ìµœê·¼ 50ê°œë§Œ ê°€ì ¸ì˜¤ê¸° (ë„ˆë¬´ ë§ìœ¼ë©´ ëŠë¦¬ë‹ˆê¹Œ)
    history = db.query(database.ChatHistory).order_by(database.ChatHistory.id.asc()).limit(50).all()
    return [{"role": h.role, "text": h.message} for h in history]

# 3. í•µì‹¬: ì±„íŒ… API (Gemini ì—°ë™)
@app.post("/api/chat")
async def chat_with_ai(request: ChatRequest, db: Session = Depends(get_db)):
    user_msg = request.message

    # (1) ìœ ì € ë©”ì‹œì§€ DB ì €ì¥
    db_user_msg = database.ChatHistory(role="user", message=user_msg)
    db.add(db_user_msg)
    db.commit()

    try:
        # (2) Geminiì—ê²Œ ì§ˆë¬¸ ë˜ì§€ê¸°
        if not GOOGLE_API_KEY:
            ai_response = "API í‚¤ê°€ ì—†ì–´ì„œ ëŒ€ë‹µí•  ìˆ˜ ì—†ì–´ìš”. docker-compose.ymlì„ í™•ì¸í•´ì£¼ì„¸ìš”."
        else:
            # generate_contentê°€ ì‹¤ì œ êµ¬ê¸€ ì„œë²„ë¡œ ì§ˆë¬¸ì„ ë³´ëƒ…ë‹ˆë‹¤.
            response = model.generate_content(user_msg)
            ai_response = response.text

    except Exception as e:
        ai_response = f"ìƒê°í•˜ë‹¤ê°€ ì—ëŸ¬ê°€ ë‚¬ì–´ìš”: {str(e)}"
        print(f"Gemini Error: {e}")

    # (3) AI ë‹µë³€ DB ì €ì¥
    db_ai_msg = database.ChatHistory(role="bot", message=ai_response)
    db.add(db_ai_msg)
    db.commit()

    return {"reply": ai_response}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)