from fastapi import FastAPI, Depends, HTTPException, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from sqlalchemy.orm import Session
from sqlalchemy import text
import database
import os
import google.generativeai as genai
import yfinance as yf
from apscheduler.schedulers.background import BackgroundScheduler
import requests
from datetime import datetime, timedelta
import math
from langchain_text_splitters import RecursiveCharacterTextSplitter
import pandas as pd

# 1. DB ì´ˆê¸°í™” ë° ë²¡í„° ìµìŠ¤í…ì…˜ í™œì„±í™”
with database.engine.connect() as con:
    con.execute(text("CREATE EXTENSION IF NOT EXISTS vector"))
    con.commit()

database.Base.metadata.create_all(bind=database.engine)

# 2. Gemini ì„¤ì •
GOOGLE_API_KEY = os.getenv("GEMINI_API_KEY")
model = None

# í…”ë ˆê·¸ë¨ ì„¤ì •
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
TELEGRAM_CHAT_ID = os.getenv("TELEGRAM_CHAT_ID")

if not GOOGLE_API_KEY:
    print("âš ï¸ ê²½ê³ : GEMINI_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤.")
else:
    genai.configure(api_key=GOOGLE_API_KEY)
    target_model = 'gemini-2.5-flash' # ë˜ëŠ” gemini-1.5-flash
    try:
        model = genai.GenerativeModel(target_model)
        print(f"âœ… AI ëª¨ë¸ '{target_model}' ë¡œë“œ ì„±ê³µ!")
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ì„¤ì • ì‹¤íŒ¨: {e}")

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- ë°ì´í„° ëª¨ë¸ ì •ì˜ ---
class ChatRequest(BaseModel):
    message: str
    model: str = "gemini-2.5-flash"

class AnalysisRequest(BaseModel):
    log_text: str

class SettingRequest(BaseModel):
    threshold: float
    is_active: bool

class ChartRequest(BaseModel):
    symbol: str = "NQ=F"
    interval: str = "1m"
    range: str = "1d"

# --- ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ---
def get_db():
    db = database.SessionLocal()
    try:
        yield db
    finally:
        db.close()

def send_telegram_msg(text):
    if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_ID:
        return
    url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
    try:
        requests.post(url, json={"chat_id": TELEGRAM_CHAT_ID, "text": text, "parse_mode": "HTML"})
    except Exception as e:
        print(f"Telegram Error: {e}")

# í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°(ìˆ«ì ë°°ì—´)ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
def get_embedding(text):
    if not GOOGLE_API_KEY: return None
    try:
        result = genai.embed_content(
            model="models/text-embedding-004",
            content=text,
            task_type="retrieval_document",
        )
        return result['embedding']
    except Exception as e:
        print(f"Embedding Error: {e}")
        return None

# --- ìŠ¤ì¼€ì¤„ëŸ¬ ë¡œì§ (ë‚˜ìŠ¤ë‹¥ ë“±ë½ ê°ì§€) ---
def fetch_market_data():
    db = database.SessionLocal()
    symbol = "NQ=F"

    try:
        ticker = yf.Ticker(symbol)
        data = ticker.history(period="1d", interval="1m")

        if data.empty:
            return

        # float ë³€í™˜ í•„ìˆ˜
        current_price = float(data['Close'].iloc[-1])

        # DB ì €ì¥
        new_price = database.MarketPrice(symbol=symbol, price=current_price)
        db.add(new_price)

        # 24ì‹œê°„ ì§€ë‚œ ë°ì´í„° ì‚­ì œ
        db.query(database.MarketPrice).filter(
            database.MarketPrice.timestamp < datetime.now() - timedelta(days=1)
        ).delete()
        db.commit()

        # ì•Œë¦¼ ì²´í¬
        setting = db.query(database.MarketSetting).first()
        if not setting:
            setting = database.MarketSetting(target_symbol=symbol, threshold_percent=1.0)
            db.add(setting)
            db.commit()

        if setting.is_active:
            # ê¸°ì¤€ê°€ ê³„ì‚° (ì˜¤ëŠ˜ ì‹œì´ˆê°€ ê¸°ì¤€)
            try:
                open_price = float(data['Open'].iloc[0])
            except:
                open_price = current_price # ì˜ˆì™¸ ì‹œ í˜„ì¬ê°€ ì‚¬ìš© (ì•Œë¦¼ ì•ˆ ê°€ë„ë¡)

            change_percent = ((current_price - open_price) / open_price) * 100

            if abs(change_percent) >= setting.threshold_percent:
                if not setting.last_alert_time or datetime.now() - setting.last_alert_time > timedelta(minutes=30):
                    direction = "ë–¡ìƒ ğŸš€" if change_percent > 0 else "ë–¡ë½ ğŸ“‰"
                    msg = f"<b>[ë‚˜ìŠ¤ë‹¥ ì•Œë¦¼]</b>\n{direction} ê°ì§€!\n\ní˜„ì¬ê°€: {current_price:.2f}\në³€ë™ë¥ : {change_percent:.2f}%\n(ì„¤ì •ê°’: {setting.threshold_percent}%)"
                    send_telegram_msg(msg)

                    setting.last_alert_time = datetime.now()
                    db.commit()

    except Exception as e:
        print(f"Market Fetch Error: {e}")
    finally:
        db.close()

@app.on_event("startup")
def start_scheduler():
    scheduler = BackgroundScheduler()
    scheduler.add_job(fetch_market_data, 'interval', minutes=1)
    scheduler.start()

# --- API ì—”ë“œí¬ì¸íŠ¸ ---

@app.get("/")
def read_root():
    return {"message": "Gemini AI Server is Running!"}

@app.get("/api/ai-status")
def get_ai_status():
    status = "Online" if model else "Offline"
    return {
        "status": status,
        "model": model.model_name if model else "None",
        "message": "AIê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤."
    }

@app.get("/api/chat/history")
def get_chat_history(db: Session = Depends(get_db)):
    history = db.query(database.ChatHistory).order_by(database.ChatHistory.id.desc()).limit(50).all()
    return [{
        "role": h.role,
        "text": h.message,
        "timestamp": h.timestamp.strftime("%Y-%m-%d %H:%M")
    } for h in history[::-1]]

# [íŒŒì¼ ì—…ë¡œë“œ] RAG
@app.post("/api/upload")
async def upload_document(file: UploadFile = File(...), db: Session = Depends(get_db)):
    try:
        content = await file.read()
        text_content = content.decode("utf-8")

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        chunks = text_splitter.split_text(text_content)

        for chunk in chunks:
            vector = get_embedding(chunk)
            if vector:
                db_chunk = database.DocumentChunk(filename=file.filename, content=chunk, embedding=vector)
                db.add(db_chunk)

        db.commit()
        return {"message": f"íŒŒì¼ '{file.filename}' í•™ìŠµ ì™„ë£Œ!", "preview": text_content[:50] + "..."}
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}")

# ğŸ‘‡ [ì‹ ê·œ ì¶”ê°€] ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ë°˜í™˜ API
@app.get("/api/ai/models")
def get_available_models():
    if not GOOGLE_API_KEY:
        return []
    try:
        # generateContentë¥¼ ì§€ì›í•˜ëŠ” Gemini ëª¨ë¸ë§Œ í•„í„°ë§
        models = [
            m.name.replace("models/", "")
            for m in genai.list_models()
            if 'generateContent' in m.supported_generation_methods and 'gemini' in m.name
        ]
        # ìµœì‹ ìˆœ ì •ë ¬ (ë‚´ë¦¼ì°¨ìˆœ)
        models.sort(reverse=True)
        return models
    except Exception as e:
        print(f"Model List Error: {e}")
        return ["gemini-2.5-flash", "gemini-1.5-flash", "gemini-1.5-pro"] # ì—ëŸ¬ ì‹œ ê¸°ë³¸ ëª©ë¡

# [ì±„íŒ…]
@app.post("/api/chat")
async def chat_with_ai(request: ChatRequest, db: Session = Depends(get_db)):
    user_msg = request.message
    selected_model_name = request.model

    print(f"ğŸ¤– [Model Check] ìš”ì²­ ëª¨ë¸: {selected_model_name}")

    # 1. ë²¡í„°í™” ë° DB ì €ì¥
    current_vector = get_embedding(user_msg)
    db_user_msg = database.ChatHistory(role="user", message=user_msg, embedding=current_vector)
    db.add(db_user_msg)
    db.commit()

    ai_response = ""
    try:
        if not model: # ì „ì—­ model ê°ì²´ ì²´í¬ (ê¸°ë³¸ ë¡œë”© í™•ì¸ìš©)
            ai_response = "AI ëª¨ë¸ ì˜¤ë¥˜: ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        else:
            # âœ¨ [í•µì‹¬ 1] êµ¬ê¸€ ê²€ìƒ‰ ë„êµ¬ ì¥ì°©! (ì¸í„°ë„· ì—°ê²°)
            # ì‚¬ìš©ìê°€ ì„ íƒí•œ ëª¨ë¸ì— 'google_search' ë„êµ¬ë¥¼ ë‹¬ì•„ì„œ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.
            tools_config = [
                {"google_search": {}}
            ]

            # ë§Œì•½ ìœ„ ë°©ì‹ë„ ì•ˆ ë˜ë©´ ì•„ì˜ˆ tools ì„¤ì •ì„ ë¹¼ê³ 
            # ìˆœìˆ˜ LLM ëª¨ë“œë¡œ ë™ì‘í•˜ê²Œ try-exceptë¡œ ê°ì‹¸ëŠ” ê²Œ ì•ˆì „í•©ë‹ˆë‹¤.
            try:
                current_model = genai.GenerativeModel(selected_model_name, tools=tools_config)
            except Exception as tool_error:
                print(f"âš ï¸ Tool Error (ê²€ìƒ‰ ê¸°ëŠ¥ ë¹„í™œì„±í™”): {tool_error}")
                # ì—ëŸ¬ ë‚˜ë©´ ë„êµ¬ ì—†ì´ ê¹¡í†µ ëª¨ë¸ë¡œ ìƒì„±
                current_model = genai.GenerativeModel(selected_model_name)

            # === ğŸ§  ê´€ë ¨ ê¸°ì–µ ê²€ìƒ‰ (Long-term Memory) ===
            memory_context = ""
            if current_vector is not None:
                memories = db.query(database.ChatHistory) \
                    .filter(database.ChatHistory.role == 'user') \
                    .filter(database.ChatHistory.id != db_user_msg.id) \
                    .order_by(database.ChatHistory.embedding.l2_distance(current_vector)) \
                    .limit(3).all() # ë„ˆë¬´ ë§ì´ ê°€ì ¸ì˜¤ë©´ í—·ê°ˆë ¤í•˜ë¯€ë¡œ 3ê°œë¡œ ì¤„ì„

                if memories:
                    memory_context = "\n".join([f"- {m.message}" for m in memories])

            # === ğŸ“‚ ë¬¸ì„œ ì§€ì‹ ê²€ìƒ‰ (RAG) ===
            doc_context = ""
            if current_vector is not None:
                docs = db.query(database.DocumentChunk) \
                    .order_by(database.DocumentChunk.embedding.l2_distance(current_vector)) \
                    .limit(2).all()
                if docs:
                    doc_context = "\n".join([d.content for d in docs])

            # âœ¨ [í•µì‹¬ 2] í”„ë¡¬í”„íŠ¸ ëŒ€ìˆ˜ìˆ  (ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ìœ ë„)
            # XML íƒœê·¸ë¥¼ ì¤„ì´ê³ , ì¹œêµ¬ê°™ì€ ì–´ì¡°ë¥¼ ê°•ì¡°í•©ë‹ˆë‹¤.
            system_prompt = f"""
            ë„ˆëŠ” ì‚¬ìš©ìì˜ ê°œì¸ ì„œë²„ë¥¼ ê´€ë¦¬í•˜ëŠ” ë˜‘ë˜‘í•˜ê³  ì„¼ìŠ¤ ìˆëŠ” AI íŒŒíŠ¸ë„ˆ 'ServerBot'ì´ì•¼.
            
            [ë„ˆì˜ ì„±ê²©ê³¼ í–‰ë™ ì§€ì¹¨]
            1. **ì¹œêµ¬ì²˜ëŸ¼ ëŒ€í™”í•´:** ë”±ë”±í•œ ë³´ê³ ì„œ ë§íˆ¬ë³´ë‹¤ëŠ” "í•´ìš”/í–ˆì–´ìš”" ê°™ì€ ë¶€ë“œëŸ¬ìš´ êµ¬ì–´ì²´ë¥¼ ì¨. ì´ëª¨ì§€(ğŸ˜Š, ğŸš€)ë„ ì ì ˆíˆ ì„ì–´ì„œ ìƒë™ê° ìˆê²Œ ë§í•´ì¤˜.
            2. **ëª¨ë¥´ë©´ ê²€ìƒ‰í•´:** ë‚ ì”¨, ì£¼ì‹, ìµœì‹  ë‰´ìŠ¤ ê°™ì€ ì •ë³´ëŠ” ë„¤ê°€ ê°€ì§„ 'êµ¬ê¸€ ê²€ìƒ‰ ë„êµ¬'ë¥¼ ì¨ì„œ ì‹¤ì‹œê°„ ì •ë³´ë¥¼ ì°¾ì•„ë´.
            3. **ê¸°ì–µë ¥:** ì•„ë˜ [ê¸°ì–µ]ê³¼ [ë¬¸ì„œ]ëŠ” ë„¤ê°€ ì•Œê³  ìˆëŠ” ë°°ê²½ì§€ì‹ì´ì•¼. ëŒ€í™” íë¦„ì— ë§ì„ ë•Œë§Œ ìì—°ìŠ¤ëŸ½ê²Œ ì–¸ê¸‰í•´. ì–µì§€ë¡œ ë¼ì›Œ ë§ì¶”ì§€ ë§ˆ.
            4. **ì „ë¬¸ì„±:** ì½”ë”©ì´ë‚˜ ì„œë²„ ë¬¸ì œëŠ” ì •í™•í•˜ê³  ê°„ê²°í•˜ê²Œ í•´ê²°ì±…ì„ ì¤˜.

            [ìš°ë¦¬ì˜ ì§€ë‚œ ëŒ€í™” ê¸°ì–µ]
            {memory_context if memory_context else "ì—†ìŒ"}

            [ì°¸ê³  ë¬¸ì„œ ë‚´ìš©]
            {doc_context if doc_context else "ì—†ìŒ"}
            """

            # ë‹¨ê¸° ê¸°ì–µ (íë¦„ ìœ ì§€)
            recent_history = db.query(database.ChatHistory) \
                .order_by(database.ChatHistory.id.desc()).limit(10).all()

            gemini_history = []
            for msg in reversed(recent_history):
                role = "user" if msg.role == "user" else "model"
                if msg.message == user_msg and msg.role == 'user': continue
                gemini_history.append({"role": role, "parts": [msg.message]})

            # ì±„íŒ… ì‹œì‘
            chat_session = current_model.start_chat(history=gemini_history)

            # ì§ˆë¬¸ ì „ì†¡
            response = chat_session.send_message(f"{system_prompt}\n\nì‚¬ìš©ì: {user_msg}")
            ai_response = response.text

    except Exception as e:
        ai_response = f"ì•—, ë¬¸ì œê°€ ìƒê²¼ì–´! ğŸ˜…\n(Error: {str(e)})"
        print(f"Gemini Error: {e}")

    # ë‹µë³€ ì €ì¥
    db_ai_msg = database.ChatHistory(role="bot", message=ai_response)
    db.add(db_ai_msg)
    db.commit()

    return {
        "reply": ai_response,
        "used_model": selected_model_name
    }

# ğŸ‘‡ [ìˆ˜ì •] í•œêµ­ì–´ ë¡œê·¸ ë¶„ì„ API
@app.post("/api/analyze/log")
async def analyze_log(request: AnalysisRequest):
    if not model: return {"reply": "AI ë¡œë“œ ì‹¤íŒ¨"}

    log_content = request.log_text[-5000:] if len(request.log_text) > 5000 else request.log_text

    # í•œêµ­ì–´ í”„ë¡¬í”„íŠ¸ ì ìš©
    prompt = f"""
    ë‹¹ì‹ ì€ ìœ ëŠ¥í•œ ì‹œë‹ˆì–´ ì‹œìŠ¤í…œ ê´€ë¦¬ìì…ë‹ˆë‹¤.
    ì•„ë˜ ë¡œê·¸ë¥¼ ë¶„ì„í•˜ì—¬ **ë°˜ë“œì‹œ í•œêµ­ì–´**ë¡œ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.
    
    [ë¡œê·¸ ë‚´ìš©]
    {log_content}
    
    [ìš”ì²­ì‚¬í•­]
    1. í•µì‹¬ ìš”ì•½ (ë¬´ìŠ¨ ì¼ì´ ìˆì—ˆëŠ”ì§€)
    2. ì—ëŸ¬ ë° ê²½ê³  ì›ì¸ ë¶„ì„
    3. êµ¬ì²´ì ì¸ í•´ê²° ëª…ë ¹ì–´ ë˜ëŠ” ë°©ì•ˆ ì œì•ˆ
    4. ê°€ë…ì„± ì¢‹ì€ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ ì‚¬ìš©
    """

    try:
        response = model.generate_content(prompt)
        return {"reply": response.text}
    except Exception as e:
        return {"reply": f"Error: {e}"}


# --- ë‚˜ìŠ¤ë‹¥ ê´€ë ¨ API ---
@app.get("/api/market/history")
def get_market_history(db: Session = Depends(get_db)):
    prices = db.query(database.MarketPrice).order_by(database.MarketPrice.id.desc()).limit(60).all()
    return [{"time": p.timestamp.strftime("%H:%M"), "price": p.price} for p in prices[::-1]]

@app.get("/api/market/setting")
def get_market_setting(db: Session = Depends(get_db)):
    setting = db.query(database.MarketSetting).first()
    if not setting: return {"threshold": 1.0, "is_active": True}
    return {"threshold": setting.threshold_percent, "is_active": bool(setting.is_active)}

@app.post("/api/market/setting")
def update_market_setting(req: SettingRequest, db: Session = Depends(get_db)):
    setting = db.query(database.MarketSetting).first()
    if not setting:
        setting = database.MarketSetting(target_symbol="NQ=F")
        db.add(setting)
    setting.threshold_percent = req.threshold
    setting.is_active = 1 if req.is_active else 0
    db.commit()
    return {"message": "ì €ì¥ë¨"}

# ì°¨íŠ¸ ë°ì´í„° API (ë””ë²„ê¹… ë° ì•ˆì „ì¥ì¹˜ ê°•í™”)
@app.post("/api/market/chart-data")
def get_realtime_chart(req: ChartRequest):
    try:
        # 1. ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        ticker = yf.Ticker(req.symbol)
        df = ticker.history(period=req.range, interval=req.interval)

        # ğŸš¨ [ë””ë²„ê¹… ë¡œê·¸] ë°ì´í„°ê°€ ë¹„ì–´ìˆìœ¼ë©´ ë¡œê·¸ ì¶œë ¥
        if df.empty:
            print(f"âš ï¸ [Chart Warning] '{req.symbol}' ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (Range: {req.range}, Interval: {req.interval})")
            return []

        # ì´ë™í‰ê· ì„  ê³„ì‚° (ë°ì´í„°ê°€ ì¶©ë¶„í•  ë•Œë§Œ)
        if len(df) >= 5: df['MA5'] = df['Close'].rolling(window=5).mean()
        if len(df) >= 20: df['MA20'] = df['Close'].rolling(window=20).mean()
        if len(df) >= 60: df['MA60'] = df['Close'].rolling(window=60).mean()
        if len(df) >= 120: df['MA120'] = df['Close'].rolling(window=120).mean()

        chart_data = []
        for index, row in df.iterrows():
            # ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬ ì™„í™”
            # ê°€ê²© ì •ë³´ê°€ ì—†ìœ¼ë©´ ìŠ¤í‚µí•˜ì§€ë§Œ, ê±°ë˜ëŸ‰ì€ ì—†ì–´ë„ ë¨
            if math.isnan(row['Open']) or math.isnan(row['Close']):
                continue

            # ì‹œê°„ëŒ€ ë³€í™˜ (UTC -> KST)
            try:
                if index.tzinfo is None:
                    dt_kst = index.tz_localize('UTC').tz_convert('Asia/Seoul')
                else:
                    dt_kst = index.tz_convert('Asia/Seoul')
            except:
                dt_kst = index # ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì‚¬ìš©

            time_str = dt_kst.strftime("%Y-%m-%d") if req.interval in ['1d', '1wk', '1mo'] else dt_kst.strftime("%H:%M")

            # ê±°ë˜ëŸ‰ NaN ì²˜ë¦¬ (0ìœ¼ë¡œ ëŒ€ì²´)
            vol = 0
            if 'Volume' in row and not math.isnan(row['Volume']):
                vol = int(row['Volume'])

            chart_data.append({
                "time": time_str,
                "open": float(row['Open']),
                "high": float(row['High']),
                "low": float(row['Low']),
                "close": float(row['Close']),
                "volume": vol,
                # MA ê°’ì´ NaNì´ë©´ Noneìœ¼ë¡œ (JSON ë³€í™˜ ì‹œ ì—ëŸ¬ ë°©ì§€)
                "ma5": float(row['MA5']) if 'MA5' in row and not math.isnan(row['MA5']) else None,
                "ma20": float(row['MA20']) if 'MA20' in row and not math.isnan(row['MA20']) else None,
                "ma60": float(row['MA60']) if 'MA60' in row and not math.isnan(row['MA60']) else None,
                "ma120": float(row['MA120']) if 'MA120' in row and not math.isnan(row['MA120']) else None
            })

        # ìµœì¢… ë°ì´í„° ê°œìˆ˜ í™•ì¸
        # print(f"âœ… [Chart Success] {req.symbol}: {len(chart_data)} rows loaded.")

        return chart_data

    except Exception as e:
        print(f"âŒ Chart Data Error ({req.symbol}): {e}")
        return []

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)