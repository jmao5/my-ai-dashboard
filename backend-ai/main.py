from fastapi import FastAPI, Depends, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from sqlalchemy.orm import Session
import database
import os
import google.generativeai as genai

# 1. DB ì´ˆê¸°í™”
database.Base.metadata.create_all(bind=database.engine)

# 2. Gemini ì„¤ì • (ì¤‘ë³µ ì½”ë“œ ì œê±° ë° ìµœì‹  ëª¨ë¸ ì„¤ì •)
GOOGLE_API_KEY = os.getenv("GEMINI_API_KEY")
model = None

if not GOOGLE_API_KEY:
    print("âš ï¸ ê²½ê³ : GEMINI_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
else:
    genai.configure(api_key=GOOGLE_API_KEY)

    # ëª¨ë¸ ê³ ì • (ê°€ì¥ ë¹ ë¥´ê³  ìµœì‹ ì¸ flash ëª¨ë¸ ì¶”ì²œ)
    target_model = 'gemini-2.5-flash'

    print(f"ğŸš€ AI ëª¨ë¸ '{target_model}' ë¡œë“œ ì¤‘...")
    try:
        model = genai.GenerativeModel(target_model)
        print("âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ì„¤ì • ì‹¤íŒ¨: {e}")

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class ChatRequest(BaseModel):
    message: str

def get_db():
    db = database.SessionLocal()
    try:
        yield db
    finally:
        db.close()

@app.get("/")
def read_root():
    return {"message": "Gemini AI Server is Running!"}

@app.get("/api/ai-status")
def get_ai_status():
    status = "Online" if model else "Offline"
    return {
        "status": status,
        "model": model.model_name if model else "None",
        "message": "AIê°€ ì´ì œ ì´ì „ ëŒ€í™”ë¥¼ ê¸°ì–µí•©ë‹ˆë‹¤! ğŸ§ "
    }

@app.get("/api/chat/history")
def get_chat_history(db: Session = Depends(get_db)):
    # ìµœì‹ ìˆœìœ¼ë¡œ ê°€ì ¸ì˜¤ë˜, ë‹¤ì‹œ ì‹œê°„ìˆœ(ê³¼ê±°->í˜„ì¬)ìœ¼ë¡œ ì •ë ¬í•´ì•¼ ì±„íŒ…ì°½ì— ì œëŒ€ë¡œ ë³´ì„
    history = db.query(database.ChatHistory).order_by(database.ChatHistory.id.desc()).limit(50).all()
    # íŒŒì´ì¬ ë¦¬ìŠ¤íŠ¸ ë’¤ì§‘ê¸° ([::-1]) -> ê³¼ê±°ë¶€í„° í˜„ì¬ ìˆœì„œë¡œ
    return [{"role": h.role, "text": h.message} for h in history[::-1]]

# 3. í•µì‹¬: ì±„íŒ… API (ê¸°ì–µë ¥ ì¶”ê°€ë¨)
@app.post("/api/chat")
async def chat_with_ai(request: ChatRequest, db: Session = Depends(get_db)):
    user_msg = request.message

    # (1) ìœ ì € ë©”ì‹œì§€ ë¨¼ì € DB ì €ì¥ (ê¸°ë¡ìš©)
    db_user_msg = database.ChatHistory(role="user", message=user_msg)
    db.add(db_user_msg)
    db.commit()

    ai_response = ""

    try:
        if not GOOGLE_API_KEY or not model:
            ai_response = "API í‚¤ê°€ ì—†ê±°ë‚˜ ëª¨ë¸ ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
        else:
            # === ğŸ”¥ ì—¬ê¸°ê°€ ìˆ˜ì •ëœ ë¶€ë¶„ì…ë‹ˆë‹¤ (ê¸°ì–µë ¥ ì£¼ì…) ===

            # 1. DBì—ì„œ ìµœê·¼ ëŒ€í™” ë‚´ì—­ ê°€ì ¸ì˜¤ê¸° (ìµœê·¼ 10ê°œ ì •ë„ê°€ ì ë‹¹)
            # ë„ˆë¬´ ë§ì´ ê°€ì ¸ì˜¤ë©´ í† í° ë¹„ìš©ì´ ë“¤ê±°ë‚˜ ëŠë ¤ì§ˆ ìˆ˜ ìˆìŒ
            recent_history = db.query(database.ChatHistory) \
                .order_by(database.ChatHistory.id.desc()) \
                .limit(10) \
                .all()

            # 2. Geminiê°€ ì´í•´í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (List[dict])
            # DBì—ì„œ ê°€ì ¸ì˜¨ ê±´ ìµœì‹ ìˆœì´ë¯€ë¡œ ë‹¤ì‹œ ë’¤ì§‘ì–´ì„œ(reversed) ì‹œê°„ìˆœìœ¼ë¡œ ë§Œë“¦
            gemini_history = []
            for msg in reversed(recent_history):
                # ìš°ë¦¬ DBì˜ role: 'user', 'bot'
                # Geminiì˜ role: 'user', 'model'
                role = "user" if msg.role == "user" else "model"

                # ë°©ê¸ˆ ì €ì¥í•œ ìœ ì € ë©”ì‹œì§€ëŠ” ì œì™¸ (send_messageí•  ë•Œ ë³´ë‚¼ ê±°ë‹ˆê¹Œ)
                # í•˜ì§€ë§Œ DBì—ëŠ” ì´ë¯¸ ì €ì¥í–ˆìœ¼ë¯€ë¡œ, DB IDê°€ í˜„ì¬ ì €ì¥í•œ ê²ƒë³´ë‹¤ ì‘ì€ ê²ƒë§Œ ê°€ì ¸ì˜¤ê±°ë‚˜
                # ê°„ë‹¨í•˜ê²ŒëŠ” ê·¸ëƒ¥ contentë§Œ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“­ë‹ˆë‹¤.
                if msg.message == user_msg and msg.role == 'user':
                    continue

                gemini_history.append({"role": role, "parts": [msg.message]})

            # 3. ê³¼ê±° ê¸°ë¡ì„ ë‹´ì•„ì„œ ì±„íŒ… ì„¸ì…˜ ì‹œì‘
            chat_session = model.start_chat(history=gemini_history)

            # 4. ì§ˆë¬¸ ì „ì†¡
            response = chat_session.send_message(user_msg)
            ai_response = response.text
            # ================================================

    except Exception as e:
        ai_response = f"ì—ëŸ¬ ë°œìƒ: {str(e)}"
        print(f"Gemini Error: {e}")

    # (3) AI ë‹µë³€ DB ì €ì¥
    db_ai_msg = database.ChatHistory(role="bot", message=ai_response)
    db.add(db_ai_msg)
    db.commit()

    return {"reply": ai_response}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)