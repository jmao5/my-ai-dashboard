from fastapi import FastAPI, Depends, HTTPException, UploadFile, File
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from sqlalchemy.orm import Session
from sqlalchemy import text
import database
import os
import google.generativeai as genai
import yfinance as yf
from apscheduler.schedulers.background import BackgroundScheduler
import requests
from datetime import datetime, timedelta
import math
from langchain_text_splitters import RecursiveCharacterTextSplitter
import pandas as pd

# 1. DB ì´ˆê¸°í™” ë° ë²¡í„° ìµìŠ¤í…ì…˜ í™œì„±í™”
with database.engine.connect() as con:
    con.execute(text("CREATE EXTENSION IF NOT EXISTS vector"))
    con.commit()

database.Base.metadata.create_all(bind=database.engine)

# 2. Gemini ì„¤ì •
GOOGLE_API_KEY = os.getenv("GEMINI_API_KEY")
model = None

# í…”ë ˆê·¸ë¨ ì„¤ì •
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
TELEGRAM_CHAT_ID = os.getenv("TELEGRAM_CHAT_ID")

if not GOOGLE_API_KEY:
    print("âš ï¸ ê²½ê³ : GEMINI_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤.")
else:
    genai.configure(api_key=GOOGLE_API_KEY)
    # ğŸ‘‡ [ìš”ì²­ì‚¬í•­] ìµœì‹  ëª¨ë¸ ìœ ì§€
    target_model = 'gemini-2.5-flash'
    try:
        model = genai.GenerativeModel(target_model)
        print(f"âœ… AI ëª¨ë¸ '{target_model}' ë¡œë“œ ì„±ê³µ!")
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ì„¤ì • ì‹¤íŒ¨: {e}")
        # ì‹¤íŒ¨ ì‹œ ì•ˆì „í•œ êµ¬ë²„ì „ìœ¼ë¡œ í´ë°±
        try:
            print("âš ï¸ 2.5 ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨. 1.5-flashë¡œ ì¬ì‹œë„í•©ë‹ˆë‹¤.")
            model = genai.GenerativeModel('gemini-1.5-flash')
        except:
            pass

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- ë°ì´í„° ëª¨ë¸ ì •ì˜ ---
class ChatRequest(BaseModel):
    message: str
    model: str = "gemini-2.5-flash" # ê¸°ë³¸ê°’

class AnalysisRequest(BaseModel):
    log_text: str

class SettingRequest(BaseModel):
    threshold: float
    is_active: bool

class ChartRequest(BaseModel):
    symbol: str = "NQ=F"
    interval: str = "1m"
    range: str = "1d"

# --- ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ---
def get_db():
    db = database.SessionLocal()
    try:
        yield db
    finally:
        db.close()

def send_telegram_msg(text):
    if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_ID:
        return
    url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
    try:
        requests.post(url, json={"chat_id": TELEGRAM_CHAT_ID, "text": text, "parse_mode": "HTML"})
    except Exception as e:
        print(f"Telegram Error: {e}")

# í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°(ìˆ«ì ë°°ì—´)ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
def get_embedding(text):
    if not GOOGLE_API_KEY: return None
    try:
        result = genai.embed_content(
            model="models/text-embedding-004",
            content=text,
            task_type="retrieval_document",
        )
        return result['embedding']
    except Exception as e:
        print(f"Embedding Error: {e}")
        return None

# --- ìŠ¤ì¼€ì¤„ëŸ¬ ë¡œì§ (ë‚˜ìŠ¤ë‹¥ ë“±ë½ ê°ì§€) ---
def fetch_market_data():
    db = database.SessionLocal()
    symbol = "NQ=F"

    try:
        ticker = yf.Ticker(symbol)
        data = ticker.history(period="1d", interval="1m")

        if data.empty:
            return

        # float ë³€í™˜ í•„ìˆ˜
        current_price = float(data['Close'].iloc[-1])

        try:
            open_price = float(data['Open'].iloc[0])
        except:
            open_price = current_price

        # DB ì €ì¥
        new_price = database.MarketPrice(symbol=symbol, price=current_price)
        db.add(new_price)
        db.query(database.MarketPrice).filter(
            database.MarketPrice.timestamp < datetime.now() - timedelta(days=1)
        ).delete()
        db.commit()

        # ì•Œë¦¼ ì²´í¬
        setting = db.query(database.MarketSetting).first()
        if not setting:
            setting = database.MarketSetting(target_symbol=symbol, threshold_percent=1.0)
            db.add(setting)
            db.commit()

        if setting.is_active:
            change_percent = ((current_price - open_price) / open_price) * 100
            if abs(change_percent) >= setting.threshold_percent:
                if not setting.last_alert_time or datetime.now() - setting.last_alert_time > timedelta(minutes=30):
                    direction = "ë–¡ìƒ ğŸš€" if change_percent > 0 else "ë–¡ë½ ğŸ“‰"
                    msg = f"<b>[ë‚˜ìŠ¤ë‹¥ ì•Œë¦¼]</b>\n{direction} ê°ì§€!\n\ní˜„ì¬ê°€: {current_price:,.2f}\në³€ë™ë¥ : {change_percent:.2f}%\n(ì„¤ì •ê°’: {setting.threshold_percent}%)"
                    send_telegram_msg(msg)
                    setting.last_alert_time = datetime.now()
                    db.commit()
    except Exception as e:
        print(f"Market Fetch Error: {e}")
    finally:
        db.close()

@app.on_event("startup")
def start_scheduler():
    scheduler = BackgroundScheduler()
    scheduler.add_job(fetch_market_data, 'interval', minutes=1)
    scheduler.start()

# --- API ì—”ë“œí¬ì¸íŠ¸ ---

@app.get("/")
def read_root():
    return {"message": "Gemini AI Server is Running!"}

@app.get("/api/ai/models")
def get_available_models():
    # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ë°˜í™˜ (2.5 í¬í•¨)
    return ["gemini-2.5-flash", "gemini-2.0-flash-exp", "gemini-1.5-pro", "gemini-1.5-flash"]

@app.get("/api/ai-status")
def get_ai_status():
    status = "Online" if model else "Offline"
    model_name = "Unknown"
    if model:
        # model ê°ì²´ ì†ì„± ì ‘ê·¼ ì‹œ ì—ëŸ¬ ë°©ì§€
        try: model_name = model.model_name
        except: model_name = "Custom Loaded"

    return {
        "status": status,
        "model": model_name,
        "message": "AIê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤."
    }

@app.get("/api/chat/history")
def get_chat_history(db: Session = Depends(get_db)):
    history = db.query(database.ChatHistory).order_by(database.ChatHistory.id.desc()).limit(50).all()
    return [{
        "role": h.role,
        "text": h.message,
        "timestamp": h.timestamp.strftime("%Y-%m-%d %H:%M")
    } for h in history[::-1]]

@app.post("/api/upload")
async def upload_document(file: UploadFile = File(...), db: Session = Depends(get_db)):
    try:
        content = await file.read()
        text_content = content.decode("utf-8")

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        chunks = text_splitter.split_text(text_content)

        for chunk in chunks:
            vector = get_embedding(chunk)
            if vector:
                db_chunk = database.DocumentChunk(filename=file.filename, content=chunk, embedding=vector)
                db.add(db_chunk)

        db.commit()
        return {"message": f"íŒŒì¼ '{file.filename}' í•™ìŠµ ì™„ë£Œ! ({len(chunks)} ì¡°ê°)", "preview": text_content[:50] + "..."}
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}")

# ğŸ‘‡ [ìµœì¢… ìˆ˜ì •] ì±„íŒ… API (ë„êµ¬ ì„¤ì • í˜¸í™˜ì„± í•´ê²°)
@app.post("/api/chat")
async def chat_with_ai(request: ChatRequest, db: Session = Depends(get_db)):
    user_msg = request.message
    selected_model_name = request.model

    print(f"ğŸ¤– ìš”ì²­ ëª¨ë¸: {selected_model_name}")

    # 1. ê¸°ì–µ ì €ì¥
    current_vector = get_embedding(user_msg)
    db_user_msg = database.ChatHistory(role="user", message=user_msg, embedding=current_vector)
    db.add(db_user_msg)
    db.commit()

    ai_response = ""
    try:
        if not GOOGLE_API_KEY:
            ai_response = "AI ëª¨ë¸ ì˜¤ë¥˜: API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤."
        else:
            # === 2. ëª¨ë¸ ìƒì„± ë° ë„êµ¬ ì„¤ì • ===
            # ê°€ì¥ í˜¸í™˜ì„±ì´ ë†’ì€ ë”•ì…”ë„ˆë¦¬ ë°©ì‹ìœ¼ë¡œ ì‹œë„í•˜ë˜, ì‹¤íŒ¨í•˜ë©´ ë„êµ¬ ì—†ì´ ìƒì„±í•˜ëŠ” 2ë‹¨ êµ¬ì¡°
            current_model = None

            # ë„êµ¬ ì„¤ì • ì‹œë„ (êµ¬ê¸€ ê²€ìƒ‰)
            try:
                tools_config = [{"google_search": {}}]
                current_model = genai.GenerativeModel(selected_model_name, tools=tools_config)
            except Exception as e:
                print(f"âš ï¸ ê²€ìƒ‰ ë„êµ¬ ì„¤ì • ì‹¤íŒ¨ (ì¼ë°˜ ëª¨ë“œë¡œ ì „í™˜): {e}")
                current_model = genai.GenerativeModel(selected_model_name)

            # === 3. RAG & Memory ===
            memory_context = ""
            if current_vector is not None:
                memories = db.query(database.ChatHistory) \
                    .filter(database.ChatHistory.role == 'user') \
                    .filter(database.ChatHistory.id != db_user_msg.id) \
                    .order_by(database.ChatHistory.embedding.l2_distance(current_vector)) \
                    .limit(3).all()
                if memories:
                    memory_context = "\n".join([f"- {m.message}" for m in memories])

            doc_context = ""
            if current_vector is not None:
                docs = db.query(database.DocumentChunk) \
                    .order_by(database.DocumentChunk.embedding.l2_distance(current_vector)) \
                    .limit(2).all()
                if docs:
                    doc_context = "\n".join([d.content for d in docs])

            # === 4. í”„ë¡¬í”„íŠ¸ ===
            system_prompt = f"""
            ë„ˆëŠ” ì‚¬ìš©ìì˜ ê°œì¸ ì„œë²„ë¥¼ ê´€ë¦¬í•˜ëŠ” ë˜‘ë˜‘í•˜ê³  ì„¼ìŠ¤ ìˆëŠ” AI ë¹„ì„œ 'ServerBot'ì´ì•¼.
            
            [ì§€ì¹¨]
            1. ì¹œêµ¬ì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•´. (ì´ëª¨ì§€ ì‚¬ìš©)
            2. ê³¼ê±° ê¸°ì–µì´ë‚˜ ë¬¸ì„œ ë‚´ìš©ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì¸ìš©í•´.
            3. ëª¨ë¥´ëŠ” ì •ë³´(ë‚ ì”¨, ì£¼ì‹ ë“±)ëŠ” êµ¬ê¸€ ê²€ìƒ‰ ë„êµ¬ë¥¼ ì‚¬ìš©í•´. (ë„êµ¬ ì‚¬ìš© ë¶ˆê°€ ì‹œ ëª¨ë¥¸ë‹¤ê³  ì†”ì§í•˜ê²Œ ë‹µë³€)
            
            [ê¸°ì–µ]
            {memory_context if memory_context else "ì—†ìŒ"}
            
            [ë¬¸ì„œ]
            {doc_context if doc_context else "ì—†ìŒ"}
            """

            # === 5. ë‹¨ê¸° ê¸°ì–µ ===
            recent_history = db.query(database.ChatHistory) \
                .order_by(database.ChatHistory.id.desc()).limit(10).all()

            gemini_history = []
            for msg in reversed(recent_history):
                role = "user" if msg.role == "user" else "model"
                if msg.message == user_msg and msg.role == 'user': continue
                gemini_history.append({"role": role, "parts": [msg.message]})

            # === 6. ì±„íŒ… ë° ì „ì†¡ ===
            chat_session = current_model.start_chat(history=gemini_history)

            # ë„êµ¬ ê´€ë ¨ ì—ëŸ¬ ë°œìƒ ì‹œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ try-except
            try:
                response = chat_session.send_message(f"{system_prompt}\n\nì§ˆë¬¸: {user_msg}")
                ai_response = response.text
            except Exception as e:
                # ë§Œì•½ google_search ê´€ë ¨ ì—ëŸ¬(400 Unknown field ë“±)ê°€ ì „ì†¡ ì¤‘ì— ë°œìƒí–ˆë‹¤ë©´?
                # ë„êµ¬ ì—†ëŠ” ëª¨ë¸ë¡œ ë‹¤ì‹œ ì‹œë„
                print(f"âš ï¸ ì „ì†¡ ì¤‘ ì—ëŸ¬ ë°œìƒ. ë„êµ¬ ì—†ì´ ì¬ì‹œë„í•©ë‹ˆë‹¤. Error: {e}")
                fallback_model = genai.GenerativeModel(selected_model_name) # ë„êµ¬ ì—†ìŒ
                response = fallback_model.generate_content(f"{system_prompt}\n\nì§ˆë¬¸: {user_msg}")
                ai_response = response.text

    except Exception as e:
        ai_response = f"ìµœì¢… ì—ëŸ¬ ë°œìƒ: {str(e)}"
        print(f"Gemini Critical Error: {e}")

    # ë‹µë³€ ì €ì¥
    db_ai_msg = database.ChatHistory(role="bot", message=ai_response)
    db.add(db_ai_msg)
    db.commit()

    return {"reply": ai_response, "used_model": selected_model_name}

# ... (ë‚˜ë¨¸ì§€ ë‚˜ìŠ¤ë‹¥, ë¡œê·¸ ë¶„ì„ APIë“¤ì€ ê·¸ëŒ€ë¡œ ìœ ì§€) ...
# ê¸°ì¡´ ì½”ë“œ í•˜ë‹¨ì˜ API í•¨ìˆ˜ë“¤ì€ ì‚­ì œí•˜ì§€ ë§ê³  ê·¸ëŒ€ë¡œ ë‘ì…”ì•¼ í•©ë‹ˆë‹¤!
# (get_market_history, get_market_setting, update_market_setting, get_realtime_chart, analyze_log ë“±)

# --- ë¡œê·¸ ë¶„ì„ ---
@app.post("/api/analyze/log")
async def analyze_log(request: AnalysisRequest):
    if not model: return {"reply": "AI ë¡œë“œ ì‹¤íŒ¨"}
    log_content = request.log_text[-5000:] if len(request.log_text) > 5000 else request.log_text
    prompt = f"System Admin Mode. Analyze this log:\n{log_content}"
    try:
        response = model.generate_content(prompt)
        return {"reply": response.text}
    except Exception as e:
        return {"reply": f"Error: {e}"}

# --- ë‚˜ìŠ¤ë‹¥ ê´€ë ¨ API ---
@app.get("/api/market/history")
def get_market_history(db: Session = Depends(get_db)):
    prices = db.query(database.MarketPrice).order_by(database.MarketPrice.id.desc()).limit(60).all()
    return [{"time": p.timestamp.strftime("%H:%M"), "price": p.price} for p in prices[::-1]]

@app.get("/api/market/setting")
def get_market_setting(db: Session = Depends(get_db)):
    setting = db.query(database.MarketSetting).first()
    if not setting: return {"threshold": 1.0, "is_active": True}
    return {"threshold": setting.threshold_percent, "is_active": bool(setting.is_active)}

@app.post("/api/market/setting")
def update_market_setting(req: SettingRequest, db: Session = Depends(get_db)):
    setting = db.query(database.MarketSetting).first()
    if not setting:
        setting = database.MarketSetting(target_symbol="NQ=F")
        db.add(setting)
    setting.threshold_percent = req.threshold
    setting.is_active = 1 if req.is_active else 0
    db.commit()
    return {"message": "ì €ì¥ë¨"}

@app.post("/api/market/chart-data")
def get_realtime_chart(req: ChartRequest):
    try:
        ticker = yf.Ticker(req.symbol)
        df = ticker.history(period=req.range, interval=req.interval)
        if df.empty: return []

        df['MA5'] = df['Close'].rolling(window=5).mean()
        df['MA20'] = df['Close'].rolling(window=20).mean()
        df['MA60'] = df['Close'].rolling(window=60).mean()
        df['MA120'] = df['Close'].rolling(window=120).mean()

        chart_data = []
        for index, row in df.iterrows():
            if math.isnan(row['Open']) or math.isnan(row['Close']): continue
            try:
                if index.tzinfo is None:
                    dt_kst = index.tz_localize('UTC').tz_convert('Asia/Seoul')
                else:
                    dt_kst = index.tz_convert('Asia/Seoul')
            except: dt_kst = index

            time_str = dt_kst.strftime("%Y-%m-%d") if req.interval in ['1d', '1wk', '1mo'] else dt_kst.strftime("%H:%M")

            vol = 0
            if 'Volume' in row and not math.isnan(row['Volume']): vol = int(row['Volume'])

            chart_data.append({
                "time": time_str,
                "open": float(row['Open']), "high": float(row['High']),
                "low": float(row['Low']), "close": float(row['Close']),
                "volume": vol,
                "ma5": float(row['MA5']) if 'MA5' in row and not math.isnan(row['MA5']) else None,
                "ma20": float(row['MA20']) if 'MA20' in row and not math.isnan(row['MA20']) else None,
                "ma60": float(row['MA60']) if 'MA60' in row and not math.isnan(row['MA60']) else None,
                "ma120": float(row['MA120']) if 'MA120' in row and not math.isnan(row['MA120']) else None
            })
        return chart_data
    except: return []

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)